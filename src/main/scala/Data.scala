package me.mpasa.resume

import java.time.YearMonth

import model._
import scalatags.Text.all._

/** Object to store my resume data */
object Data {

  //--------------------------------------------------------------------------------------------------------------------
  //                                               Personal information
  //--------------------------------------------------------------------------------------------------------------------

  val personal = PersonalData(
    name = "Miguel",
    lastName = "Pérez Pasalodos",
    email = "miguel.perez.pasalodos@gmail.com",
    github = Link(anchor = "mpasa", url = "https://github.com/mpasa"),
    x = Link(anchor = "Kamugo", url = "https://x.com/Kamugo"),
    webpage = Link(anchor = "mpasa.me", url = "https://mpasa.me"),
    description = div(
      """
        I'm Miguel, a Computer Scientist from Barcelona. I'm passionate about data, functional programming (mainly
        Scala), distributed systems, algorithms and mountains. I'm very pragmatic and demanding with the things I
        build, but I also love to experiment with new languages and technologies.
      """
    )
  )

  //--------------------------------------------------------------------------------------------------------------------
  //                                                    Experience
  //--------------------------------------------------------------------------------------------------------------------

  val seniorEngineeringManagerVerve = Job(
    company = "Verve",
    title = "Senior Engineering Manager, Data Platform",
    dates = Dates(YearMonth.of(2023, 9), Some(YearMonth.of(2025, 3))),
    description = div(
      p("Verve Group is a global ad platform connecting brands and publishers to people in real-time."),
      p("Started as a data engineer and transitioned into an engineering manager role, scaling the data team from 2 to 9 engineers. The team owned the end-to-end data platform, spanning infrastructure, ingestion, processing, analytics, and database management, operating at petabyte scale."),
      p("Focused on delivering business value through modern data technologies while keeping infrastructure growth efficient and cost-aware. Built and led a highly motivated team by promoting technical ownership, continuous learning, and exposure to complex, high-impact problems, ensuring engineers remained challenged while staying aligned with real business needs."),
      p(
        "Non-exhaustive tech stack:",
        ul(
          li("Scala/Python"),
          li("Airflow"),
          li("Apache Spark and Delta"),
          li("Kubernetes"),
          li("Kafka"),
          li("Apache Druid"),
          li("GCP ecosystem (GCS, BigQuery)"),
          li("AWS ecosystem (S3, Athena)"),
          li("Trino"),
          li("Prometheus/Grafana"),
        )
      )
    ),
    extra = div("")
  )

  val sabbatical2025 = Sabbatical(
    dates = Dates(YearMonth.of(2025, 4))
  )
  
  val engManagerVerve = Job(
    company = "Verve",
    title = "Engineering Manager, Data Platform",
    dates = Dates(YearMonth.of(2022, 11), Some(YearMonth.of(2023, 8))),
    description = div(""),
    extra = div("")
  )

  val leadDataEngineerVerve = Job(
    company = "Verve",
    title = "Lead Data Engineer",
    dates = Dates(YearMonth.of(2020, 2), Some(YearMonth.of(2022, 10))),
    description = div(""),
    extra = div("")
  )

  val dataEngineerPubNative = Job(
    company = "Verve",
    title = "Data Engineer",
    dates = Dates(YearMonth.of(2019, 7), Some(YearMonth.of(2020, 1))),
    description = div(""),
    extra = div("")
  )

  val sabbatical2018 = Sabbatical(
    dates = Dates(YearMonth.of(2018, 1), Some(YearMonth.of(2019, 6)))
  )

  val dataEngineerTrovit = Job(
    company = "Trovit",
    title = "Data Engineer",
    dates = Dates(YearMonth.of(2015, 7), Some(YearMonth.of(2017, 12))),
    description = div(
      p(
        """
          I worked in the Data team. We helped the company leverage the data generated by the users and other
          departments using distributed computing. We also managed a self-hosted YARN cluster (with both Hadoop and
          Spark jobs) of about 60 hosts.
        """
      ),
      p(
        """
          I led the keywords management and other related batch data pipelines. A keyword is just a set of tokens
          related to content. The goal of the pipeline was to manage all the keywords and, thus, the visibility of
          all the content to search engines. The total number of keywords exceeded the hundreds of millions, and the
          pipeline consisted of different phases:
        """
      ),
      ol(
        li("Check if new keywords could be generated"),
        li(
          "Simulate the number of results of each keyword (the ones without a minimum quantity of content are useless)"
        ),
        li("Categorize and contextualize the tokens (what does the keyword really mean?)"),
        li("Relate keywords with each other to generate linking (by hierarchy, clustering...)"),
        li("Check which keywords are worth indexing and generate a Solr index with them")
      ),
      p(
        s"""
          The pipeline was implemented using a hybrid """,
        strong("Hadoop-Spark"),
        """ batch pipeline. It was
          challenging in many ways: performance issues, lack of context (the same token could mean a lot of different
          things), dealing with search engines performance, dealing with different languages, etc.
        """
      )
    ),
    extra = div(
      p(strong("Other projects"), " I worked on:"),
      ul(
        li(
          s"""
             Ads categorization, deduplication, sorting and automatic expiration. """,
          strong("Kafka"),
          """, was used
             to enqueue the downloaded ads. A """,
          strong("Hadoop"),
          """ ecosystem (YARN, HDFS and MapReduce) was used
             to consume, process and analyse them. Finally, """,
          strong("Solr"),
          """ indices were built with all the
             processed information and deployed to production.
          """
        ),
        li(
          s"""
             Stats processing. We used Kafka to enqueue impressions, clicks, e-mail openings and conversions from the
             site. Then, different Hadoop ETL pipelines processed the queues and extracted useful information for the
             company. Finally, the data was persisted to """,
          strong("Hive"),
          """, """,
          strong("Impala"),
          """ or MySQL
             so, it could be consumed more easily.
          """
        )
      )
    )
  )

  val webDeveloperTrovit = Job(
    company = "Trovit",
    dates = Dates(YearMonth.of(2014, 7), Some(YearMonth.of(2015, 7))),
    title = "Full Stack Web Developer",
    description = div(
      p(
        """
          I worked developing different experimental Web projects expected to be an important part of the company in the
          future. The most important one was the "Publish Your Ad" project, where users could post their own ads
          directly on Trovit (which was a pure aggregator before that).
        """
      )
    ),
    extra = div(
      p("Some of the technologies I used were:"),
      ul(
        Seq(
          "PHP (Composer)",
          "Javascript (jQuery, backbone, requirejs, zepto)",
          "MySQL",
          "Amazon S3"
        ).map(li(_))
      )
    )
  )

  val webDeveloperUPC = Job(
    company = "Polytechnic University of Catalonia (UPC)",
    dates = Dates(YearMonth.of(2012, 3), Some(YearMonth.of(2013, 8))),
    title = "Internship as Web Developer and Systems Administrator",
    description = div(
      p(
        """
          I worked in the TSC (Signal Theory and Communications) department. I started helping to manage the
          department's data center (servers and network). Later on, I started developing both front-end and back-end
          web tools, which were used to improve the management of the department.
        """
      )
    ),
    extra = div(
      p("Some of the technologies I used were:"),
      ul(
        Seq(
          "Apache 2",
          "PHP (Symfony 2 framework)",
          "SQL (MySQL)",
          "Javascript (jQuery framework)",
          "LDAP",
          "Bash"
        ).map(li(_))
      )
    )
  )

  //--------------------------------------------------------------------------------------------------------------------
  //                                                    Education
  //--------------------------------------------------------------------------------------------------------------------

  val upc = Education(
    dates = Dates(YearMonth.of(2009, 9), Some(YearMonth.of(2014, 4))),
    title = "Bachelor’s degree in Informatics Engineering",
    organization = "Barcelona School of Informatics (FIB), Universitat Politècnica de Catalunya (UPC).",
    skills = p(
      s"""
        Major in """,
      strong("Computing"),
      """. I was trained to assess the difficulty of computing problems, to
        identify the most suitable machines, languages and programming paradigms, and to design and implement the best
        IT solution.
      """
    ),
    notes = Some(
      p(
        s"""
        I successfully finished different advanced computing modules, including Theory of Computation, Machine
        Learning, Advanced Algorithms and Distributed Intelligent Systems.
      """
      )
    )
  )

  //--------------------------------------------------------------------------------------------------------------------
  //                                                  Certifications
  //--------------------------------------------------------------------------------------------------------------------

  val sparkML = Certification(
    name = "Verified Certificate for Scalable Machine Learning",
    dates = Dates(YearMonth.of(2015, 8), Some(YearMonth.of(2015, 8))),
    organization = "edX",
    skills = div(
      s"""
        I learned how machine learning algorithms could be adapted and used in large clusters of commodity machines.
        Particularly, I used """,
      strong("Apache Spark"),
      """ to resolve different machine learning problems.
      """
    )
  )

  //--------------------------------------------------------------------------------------------------------------------
  //                                                   Publications
  //--------------------------------------------------------------------------------------------------------------------

  val assistiveSocialNetwork = Publication(
    title = "Using Multi-Agent Systems to mediate in an assistive social network for elder population",
    date = Dates.single(YearMonth.of(2015, 10)),
    coAuthors = Seq("Cristian Barrué", "Ulises Cortés", "Atia Cortés", "Jonatan Moreno"),
    abs = """
        Nowadays ubiquitous connectivity, portable computing, pervasive sensing, novel interfaces, cheap and fast
        computing units, and advances in robotic devices and actuators are changing our lives, our living
        environments, and our social interaction. To truly benefit the elderly and fragile population, commodities
        based on these novel technologies need to be autonomous and interactive, and must be capable of anticipating
        user needs, managing complex and unforeseen situations on their own, seamlessly interfacing with casual
        end-users, and gracefully terminating their functioning when unrecoverable errors occur. Our main aim is to
        provide a model for developing a multi-agent system integrated into a medical social network. It must
        provide a tool for developing assistive services to support elderly patients with disabilities in their daily
        life.
      """
  )

  //--------------------------------------------------------------------------------------------------------------------
  //                                                      Resume
  //--------------------------------------------------------------------------------------------------------------------

  val resume = Resume(
    personalData = personal,
    experience = Seq(
      sabbatical2025,
      seniorEngineeringManagerVerve,
      engManagerVerve,
      leadDataEngineerVerve,
      dataEngineerPubNative,
      sabbatical2018,
      dataEngineerTrovit,
      webDeveloperTrovit,
      webDeveloperUPC
    ),
    education = Seq(upc),
    certifications = Seq(sparkML),
    languages = Seq(
      NativeLanguage("Spanish"),
      NativeLanguage("Catalan"),
      ForeignLanguage(name = "English", listening = C1, reading = C1, writing = C1, speaking = C1)
    ),
    publications = Seq(assistiveSocialNetwork)
  )

}
